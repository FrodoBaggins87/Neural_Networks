{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "o2cKzJZObJ7A",
        "HBGKV32obXbS",
        "DHB2tEIOcC_n",
        "LzsTMAuacNgW",
        "aWYcINGfiSZ4",
        "auzprawxk9Su",
        "vLTJdUrKl7qr",
        "kQIlQwuHV3yC"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQl8CX9qcLDZhciXgtSm9K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2a774b80d53845568e391d6786a9ecb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7dfc49ef20474b80919bb26cdf536f61",
              "IPY_MODEL_590bd1e196304f7da95132671a16ddd9",
              "IPY_MODEL_a2ad59f18fd1447bb650eaacbf42da6d"
            ],
            "layout": "IPY_MODEL_aa89cf4124e94e60bedf608f0110424c"
          }
        },
        "7dfc49ef20474b80919bb26cdf536f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63438acf3403440e9e5a9d6f6393cdb0",
            "placeholder": "​",
            "style": "IPY_MODEL_4ce57529dde64053965dedf6156914de",
            "value": " 75%"
          }
        },
        "590bd1e196304f7da95132671a16ddd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f6b72f2ecfb454bb30c1b8e2c5e25b9",
            "max": 20,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0df22fd22e8747078bb9a2f70f45e110",
            "value": 15
          }
        },
        "a2ad59f18fd1447bb650eaacbf42da6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ba0cb230ff1d40ebb0823fa42012093f",
            "placeholder": "​",
            "style": "IPY_MODEL_3a63b85015b748b4a9276a5b776f7d74",
            "value": " 15/20 [51:54&lt;17:07, 205.56s/it]"
          }
        },
        "aa89cf4124e94e60bedf608f0110424c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63438acf3403440e9e5a9d6f6393cdb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ce57529dde64053965dedf6156914de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f6b72f2ecfb454bb30c1b8e2c5e25b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df22fd22e8747078bb9a2f70f45e110": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ba0cb230ff1d40ebb0823fa42012093f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a63b85015b748b4a9276a5b776f7d74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FrodoBaggins87/Neural_Networks/blob/main/FoodDetector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting up"
      ],
      "metadata": {
        "id": "o2cKzJZObJ7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p4HZ08RDahkX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5528e54e-24cf-4b08-d40f-6dd7f813738a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available libraries not updated, downloading updated libraries\n",
            "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cu113\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.1+cu121)\n",
            "Collecting torch\n",
            "  Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Collecting torchvision\n",
            "  Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading torch-2.4.0-cp310-cp310-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading torchvision-0.19.0-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.3.1\n",
            "    Uninstalling triton-2.3.1:\n",
            "      Successfully uninstalled triton-2.3.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.3.1+cu121\n",
            "    Uninstalling torch-2.3.1+cu121:\n",
            "      Successfully uninstalled torch-2.3.1+cu121\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.18.1+cu121\n",
            "    Uninstalling torchvision-0.18.1+cu121:\n",
            "      Successfully uninstalled torchvision-0.18.1+cu121\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.15 requires torch<2.4,>=1.10, but you have torch 2.4.0 which is incompatible.\n",
            "torchaudio 2.3.1+cu121 requires torch==2.3.1, but you have torch 2.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 torchvision-0.19.0 triton-3.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "096071b94c754c9f973caf32724d9aa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastai in /usr/local/lib/python3.10/dist-packages (2.7.15)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai) (24.1)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.6,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.5.54)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai) (0.19.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fastai) (2.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fastai) (2.31.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai) (6.0.1)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai) (9.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fastai) (1.3.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fastai) (1.13.1)\n",
            "Requirement already satisfied: spacy<4 in /usr/local/lib/python3.10/dist-packages (from fastai) (3.7.5)\n",
            "Collecting torch<2.4,>=1.10 (from fastai)\n",
            "  Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (4.66.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (71.0.4)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4->fastai) (1.25.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fastai) (2024.7.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (12.1.105)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.4,>=1.10->fastai)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch<2.4,>=1.10->fastai) (12.1.105)\n",
            "Collecting triton==2.3.1 (from torch<2.4,>=1.10->fastai)\n",
            "  Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.4,>=1.10->fastai) (12.5.82)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision>=0.11 (from fastai)\n",
            "  Downloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fastai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fastai) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fastai) (3.5.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4->fastai) (2.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->fastai) (1.16.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4->fastai) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<4->fastai) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<4->fastai) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4->fastai) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch<2.4,>=1.10->fastai) (1.3.0)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4->fastai) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4->fastai) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4->fastai) (0.1.2)\n",
            "Downloading torch-2.3.1-cp310-cp310-manylinux1_x86_64.whl (779.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m779.1/779.1 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Downloading triton-2.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.18.1-cp310-cp310-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m108.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-cudnn-cu12, torch, torchvision\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.0.0\n",
            "    Uninstalling triton-3.0.0:\n",
            "      Successfully uninstalled triton-3.0.0\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.1.0.70\n",
            "    Uninstalling nvidia-cudnn-cu12-9.1.0.70:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.1.0.70\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.4.0\n",
            "    Uninstalling torch-2.4.0:\n",
            "      Successfully uninstalled torch-2.4.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.19.0\n",
            "    Uninstalling torchvision-0.19.0:\n",
            "      Successfully uninstalled torchvision-0.19.0\n",
            "Successfully installed nvidia-cudnn-cu12-8.9.2.26 torch-2.3.1 torchvision-0.18.1 triton-2.3.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen",
                  "torchvision"
                ]
              },
              "id": "c0c75220e2334f3ab97f87c3734dd307"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version:2.3.1+cu121\n",
            "torchvision version:0.18.1+cu121\n"
          ]
        }
      ],
      "source": [
        "#we need Torch 1.12 + and Torchvision 0.13 + for this study\n",
        "try:\n",
        "  import torch, torchvision\n",
        "  assert int(torch.__version__.split(\".\")[1])>=12, \"Torch version should be 1.12 or above\"\n",
        "  assert int(torchvision.__version__.split(\".\")[1])>=13, \"Torch version should be 0.12 or above\"\n",
        "  print(f\"Torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")\n",
        "except:\n",
        "  print(\"Available libraries not updated, downloading updated libraries\")\n",
        "  !pip3 install -U torch torchvision --extra-index-url https://download.pytorch.org/whl/cu113\n",
        "  !pip3 install --upgrade fastai\n",
        "\n",
        "  import torch, torchvision\n",
        "  print(f\"Torch version:{torch.__version__}\")\n",
        "  print(f\"torchvision version:{torchvision.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "try:\n",
        "  from torchinfo import summary\n",
        "except:\n",
        "  !pip install -q torchinfo\n",
        "  from torchinfo import summary"
      ],
      "metadata": {
        "id": "2HMejEWXbUcU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reusable scripts"
      ],
      "metadata": {
        "id": "HBGKV32obXbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_setup.py"
      ],
      "metadata": {
        "id": "QOTdwgyDb3Y7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile data_setup.py\n",
        "import os\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "NUM_WORKERS= os.cpu_count()\n",
        "def create_dataloaders(\n",
        "    train_dir: str,\n",
        "    test_dir:str,\n",
        "    train_transform: transforms.Compose,\n",
        "    test_transform: transforms.Compose,\n",
        "    batch_size:int,\n",
        "    num_workers: int=NUM_WORKERS\n",
        "):\n",
        "\n",
        "  training_data=datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "  testing_data=datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "  class_names=training_data.classes\n",
        "  train_dataloader=DataLoader(dataset=training_data,\n",
        "                              batch_size=batch_size,#sample per dataloader\n",
        "                              num_workers=num_workers,\n",
        "                              shuffle=True,\n",
        "                              pin_memory= True)\n",
        "  test_dataloader=DataLoader(dataset=testing_data,\n",
        "                            batch_size=batch_size,\n",
        "                            num_workers=num_workers,\n",
        "                            shuffle=False,\n",
        "                            pin_memory= True)\n",
        "  return train_dataloader, test_dataloader, class_names\n"
      ],
      "metadata": {
        "id": "4X8wkSXWbfVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf04d98-3d24-4915-b9bf-0e232bd6c410"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "engine.py"
      ],
      "metadata": {
        "id": "-waZTEOBbzej"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile engine.py\n",
        "import torch\n",
        "\n",
        "from tqdm.auto import tqdm\n",
        "from typing import Dict, List, Tuple\n",
        "def train_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "               optimizer:torch.optim.Optimizer,\n",
        "              device: torch.device) -> Tuple[float, float]:\n",
        "  #putting in training mode\n",
        "  model.train()\n",
        "  #setup training loss and training accuracy\n",
        "  train_loss,train_acc=0,0\n",
        "\n",
        "  for batch,(x,y) in enumerate(dataloader):\n",
        "    #send data to target device\n",
        "    x,y=x.to(device),y.to(device)\n",
        "    #forward pass\n",
        "    y_pred=model(x)\n",
        "    #calculate and accumulate losses\n",
        "    loss=loss_fn(y_pred,y)\n",
        "    train_loss+=loss.item()\n",
        "    #optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    #loss backward\n",
        "    loss.backward()\n",
        "    #optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    #calculate and accumulate accuracy metric for all batches\n",
        "    y_pred_class=torch.argmax(torch.softmax(y_pred,dim=1),dim=1)\n",
        "    train_acc+=(y_pred_class==y).sum().item()/len(y_pred)\n",
        "\n",
        "  #getting average loss and accuracy for each batch\n",
        "  train_loss/=len(dataloader)\n",
        "  train_acc/=len(dataloader)\n",
        "  return train_loss, train_acc\n",
        "\n",
        "def test_step(model:torch.nn.Module,\n",
        "               dataloader:torch.utils.data.DataLoader,\n",
        "               loss_fn:torch.nn.Module,\n",
        "              device: torch.device) -> Tuple[float,float]:\n",
        "  #putting in eval mode\n",
        "  model.eval()\n",
        "  #setup test loss and test accuracy\n",
        "  test_loss,test_acc=0,0\n",
        "  #turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    #loop through dataloader batches\n",
        "    for batch,(x,y) in enumerate(dataloader):\n",
        "      #send data to target device\n",
        "      x,y=x.to(device),y.to(device)\n",
        "      #forward pass\n",
        "      test_pred_logits=model(x)\n",
        "      #calculate and accumulate loss\n",
        "      loss=loss_fn(test_pred_logits,y)\n",
        "      test_loss+=loss.item()\n",
        "      #calculate and accumulate accuracy\n",
        "      test_pred_labels=torch.argmax(torch.softmax(test_pred_logits,dim=1),dim=1)\n",
        "      test_acc+=(test_pred_labels==y).sum().item()/len(test_pred_labels)#can probably also use len(test_pred), not sure both should work i think\n",
        "  #getting average loss and accuracy for each batch\n",
        "  test_acc/=len(dataloader)\n",
        "  test_loss/=len(dataloader)\n",
        "  return test_loss, test_acc\n",
        "\n",
        "#defining functions and various required parameters\n",
        "def train(model:torch.nn.Module,\n",
        "          train_dataloader:torch.utils.data.DataLoader,\n",
        "          test_dataloader:torch.utils.data.DataLoader,\n",
        "          optimizer:torch.optim.Optimizer,\n",
        "          loss_fn:torch.nn.Module,\n",
        "          scheduler:torch.optim.lr_scheduler._LRScheduler,\n",
        "          epochs: int,\n",
        "        device: torch.device) -> Dict[str, list]:\n",
        "  #create empty results dictionary\n",
        "  results={\"train_loss\":[],\n",
        "           \"test_loss\":[],\n",
        "           \"train_acc\":[],\n",
        "           \"test_acc\":[]}\n",
        "  #looping through train_step() and test_step()\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss,train_acc=train_step(model=model,\n",
        "                                    dataloader=train_dataloader,\n",
        "                                    loss_fn=loss_fn,\n",
        "                                    optimizer=optimizer,\n",
        "                                    device=device)\n",
        "    test_loss, test_acc=test_step(model=model,\n",
        "                                  dataloader=test_dataloader,\n",
        "                                  loss_fn=loss_fn,\n",
        "                                  device=device)\n",
        "    #print whats happening every epoch\n",
        "    print(\n",
        "        f\"Epoch:{epoch+1}|\"\n",
        "        f\"Train Loss:{train_loss:.4f}|\"\n",
        "        f\"Training Accuracy: {train_acc:.4f}|\"\n",
        "        f\"Test Loss: {test_loss:.4f}|\"\n",
        "        f\"Test Accuracy: {test_acc:.4f}\"\n",
        "    )\n",
        "    #updating result dictionary every epoch\n",
        "    results[\"train_loss\"].append(train_loss)\n",
        "    results[\"test_loss\"].append(test_loss)\n",
        "    results[\"train_acc\"].append(train_acc)\n",
        "    results[\"test_acc\"].append(test_acc)\n",
        "\n",
        "    #scheduler step\n",
        "    scheduler.step(test_loss)\n",
        "\n",
        "  #return results dictionary\n",
        "  return results\n"
      ],
      "metadata": {
        "id": "IpicpT7bb0Gp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1805eb5-b4d3-4e16-8614-d43817fae316"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "utils.py"
      ],
      "metadata": {
        "id": "MPmAPJRrb-A3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "def save_model(model:torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name:str):\n",
        "  #creating target directory\n",
        "  target_dir_path=Path(target_dir)\n",
        "  target_dir_path.mkdir(parents=True,\n",
        "                        exist_ok=True)\n",
        "  #creating model save path\n",
        "  assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"model_name should end with '.pt' or '.pth'\"\n",
        "  model_save_path = target_dir_path/model_name\n",
        "\n",
        "  #save the model state_dict\n",
        "  print(f\"Saving model to:{model_save_path}\")\n",
        "  torch.save(obj=model.state_dict(),\n",
        "             f=model_save_path)"
      ],
      "metadata": {
        "id": "IeXUN_Ekb9pJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6fef91-a44c-4f98-f143-64cd35c0feb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "effnet_b2.py"
      ],
      "metadata": {
        "id": "sU8ebc3egW_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile effnet_b2.py\n",
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "def create_effnet_b2(device:str,num_classes:int,seed:int=69):\n",
        "  #1\n",
        "  weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  transforms=weights.transforms()\n",
        "  model=torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
        "\n",
        "  #2. freeze all parameters in all layers\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "  #3. set random seeds\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)\n",
        "\n",
        "  #4. changing classifier layer\n",
        "  model.classifier= torch.nn.Sequential(nn.Dropout(p=0.2, inplace=True),\n",
        "                                        nn.Linear(in_features=1408,\n",
        "                                                  out_features=num_classes,\n",
        "                                                  bias=True).to(device))\n",
        "  #5. give name\n",
        "  model.name='effnet_b2'\n",
        "  print(f\"Making EfficientNet_B2\")\n",
        "\n",
        "  return model,weights,transforms"
      ],
      "metadata": {
        "id": "MLwLlKCIgX4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f2df33-0b59-46dc-ee8d-3a132c5e304a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting effnet_b2.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Device agnostic code"
      ],
      "metadata": {
        "id": "DHB2tEIOcC_n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "lMYfmATBcKIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "847738ce-9bff-4cb0-8180-dfc95b30cda7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Random seed function"
      ],
      "metadata": {
        "id": "LzsTMAuacNgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#set seeds\n",
        "def set_seeds(seed:int=69):\n",
        "  \"set seed whenever required before torch operations. Default seed = 69\"\n",
        "  torch.manual_seed(seed)\n",
        "  torch.cuda.manual_seed(seed)"
      ],
      "metadata": {
        "id": "7OljzLZYcRVU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting an EffNet_B2 model"
      ],
      "metadata": {
        "id": "aWYcINGfiSZ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import effnet_b2\n",
        "effnet_model,_,effnet_transforms=effnet_b2.create_effnet_b2(num_classes=101,device=device)\n"
      ],
      "metadata": {
        "id": "guKLY_MKiVFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f49f32a-8c3c-4165-84eb-fd8b14b73a93"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b2_rwightman-c35c1473.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b2_rwightman-c35c1473.pth\n",
            "100%|██████████| 35.2M/35.2M [00:01<00:00, 33.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Making EfficientNet_B2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchinfo import summary\n",
        "summary(effnet_model,\n",
        "        input_size=(1,3,224,224),\n",
        "        col_names=['input_size', 'output_size','num_params','trainable'])\n"
      ],
      "metadata": {
        "id": "cMnGk0kQkGdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6c3bc4-8f52-449d-d661-0ef0cf66e692"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "===========================================================================================================================================================\n",
              "Layer (type:depth-idx)                                  Input Shape               Output Shape              Param #                   Trainable\n",
              "===========================================================================================================================================================\n",
              "EfficientNet                                            [1, 3, 224, 224]          [1, 101]                  --                        Partial\n",
              "├─Sequential: 1-1                                       [1, 3, 224, 224]          [1, 1408, 7, 7]           --                        False\n",
              "│    └─Conv2dNormActivation: 2-1                        [1, 3, 224, 224]          [1, 32, 112, 112]         --                        False\n",
              "│    │    └─Conv2d: 3-1                                 [1, 3, 224, 224]          [1, 32, 112, 112]         (864)                     False\n",
              "│    │    └─BatchNorm2d: 3-2                            [1, 32, 112, 112]         [1, 32, 112, 112]         (64)                      False\n",
              "│    │    └─SiLU: 3-3                                   [1, 32, 112, 112]         [1, 32, 112, 112]         --                        --\n",
              "│    └─Sequential: 2-2                                  [1, 32, 112, 112]         [1, 16, 112, 112]         --                        False\n",
              "│    │    └─MBConv: 3-4                                 [1, 32, 112, 112]         [1, 16, 112, 112]         (1,448)                   False\n",
              "│    │    └─MBConv: 3-5                                 [1, 16, 112, 112]         [1, 16, 112, 112]         (612)                     False\n",
              "│    └─Sequential: 2-3                                  [1, 16, 112, 112]         [1, 24, 56, 56]           --                        False\n",
              "│    │    └─MBConv: 3-6                                 [1, 16, 112, 112]         [1, 24, 56, 56]           (6,004)                   False\n",
              "│    │    └─MBConv: 3-7                                 [1, 24, 56, 56]           [1, 24, 56, 56]           (10,710)                  False\n",
              "│    │    └─MBConv: 3-8                                 [1, 24, 56, 56]           [1, 24, 56, 56]           (10,710)                  False\n",
              "│    └─Sequential: 2-4                                  [1, 24, 56, 56]           [1, 48, 28, 28]           --                        False\n",
              "│    │    └─MBConv: 3-9                                 [1, 24, 56, 56]           [1, 48, 28, 28]           (16,518)                  False\n",
              "│    │    └─MBConv: 3-10                                [1, 48, 28, 28]           [1, 48, 28, 28]           (43,308)                  False\n",
              "│    │    └─MBConv: 3-11                                [1, 48, 28, 28]           [1, 48, 28, 28]           (43,308)                  False\n",
              "│    └─Sequential: 2-5                                  [1, 48, 28, 28]           [1, 88, 14, 14]           --                        False\n",
              "│    │    └─MBConv: 3-12                                [1, 48, 28, 28]           [1, 88, 14, 14]           (50,300)                  False\n",
              "│    │    └─MBConv: 3-13                                [1, 88, 14, 14]           [1, 88, 14, 14]           (123,750)                 False\n",
              "│    │    └─MBConv: 3-14                                [1, 88, 14, 14]           [1, 88, 14, 14]           (123,750)                 False\n",
              "│    │    └─MBConv: 3-15                                [1, 88, 14, 14]           [1, 88, 14, 14]           (123,750)                 False\n",
              "│    └─Sequential: 2-6                                  [1, 88, 14, 14]           [1, 120, 14, 14]          --                        False\n",
              "│    │    └─MBConv: 3-16                                [1, 88, 14, 14]           [1, 120, 14, 14]          (149,158)                 False\n",
              "│    │    └─MBConv: 3-17                                [1, 120, 14, 14]          [1, 120, 14, 14]          (237,870)                 False\n",
              "│    │    └─MBConv: 3-18                                [1, 120, 14, 14]          [1, 120, 14, 14]          (237,870)                 False\n",
              "│    │    └─MBConv: 3-19                                [1, 120, 14, 14]          [1, 120, 14, 14]          (237,870)                 False\n",
              "│    └─Sequential: 2-7                                  [1, 120, 14, 14]          [1, 208, 7, 7]            --                        False\n",
              "│    │    └─MBConv: 3-20                                [1, 120, 14, 14]          [1, 208, 7, 7]            (301,406)                 False\n",
              "│    │    └─MBConv: 3-21                                [1, 208, 7, 7]            [1, 208, 7, 7]            (686,868)                 False\n",
              "│    │    └─MBConv: 3-22                                [1, 208, 7, 7]            [1, 208, 7, 7]            (686,868)                 False\n",
              "│    │    └─MBConv: 3-23                                [1, 208, 7, 7]            [1, 208, 7, 7]            (686,868)                 False\n",
              "│    │    └─MBConv: 3-24                                [1, 208, 7, 7]            [1, 208, 7, 7]            (686,868)                 False\n",
              "│    └─Sequential: 2-8                                  [1, 208, 7, 7]            [1, 352, 7, 7]            --                        False\n",
              "│    │    └─MBConv: 3-25                                [1, 208, 7, 7]            [1, 352, 7, 7]            (846,900)                 False\n",
              "│    │    └─MBConv: 3-26                                [1, 352, 7, 7]            [1, 352, 7, 7]            (1,888,920)               False\n",
              "│    └─Conv2dNormActivation: 2-9                        [1, 352, 7, 7]            [1, 1408, 7, 7]           --                        False\n",
              "│    │    └─Conv2d: 3-27                                [1, 352, 7, 7]            [1, 1408, 7, 7]           (495,616)                 False\n",
              "│    │    └─BatchNorm2d: 3-28                           [1, 1408, 7, 7]           [1, 1408, 7, 7]           (2,816)                   False\n",
              "│    │    └─SiLU: 3-29                                  [1, 1408, 7, 7]           [1, 1408, 7, 7]           --                        --\n",
              "├─AdaptiveAvgPool2d: 1-2                                [1, 1408, 7, 7]           [1, 1408, 1, 1]           --                        --\n",
              "├─Sequential: 1-3                                       [1, 1408]                 [1, 101]                  --                        True\n",
              "│    └─Dropout: 2-10                                    [1, 1408]                 [1, 1408]                 --                        --\n",
              "│    └─Linear: 2-11                                     [1, 1408]                 [1, 101]                  142,309                   True\n",
              "===========================================================================================================================================================\n",
              "Total params: 7,843,303\n",
              "Trainable params: 142,309\n",
              "Non-trainable params: 7,700,994\n",
              "Total mult-adds (M): 657.78\n",
              "===========================================================================================================================================================\n",
              "Input size (MB): 0.60\n",
              "Forward/backward pass size (MB): 156.80\n",
              "Params size (MB): 31.37\n",
              "Estimated Total Size (MB): 188.77\n",
              "==========================================================================================================================================================="
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make separate transform for training dataset"
      ],
      "metadata": {
        "id": "auzprawxk9Su"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "food_101_transform=transforms.Compose([transforms.TrivialAugmentWide(),\n",
        "                                       effnet_transforms])"
      ],
      "metadata": {
        "id": "hFUj0frXlBGB"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Training data transform:{food_101_transform}')\n",
        "print(f'Testing data transform:{effnet_transforms}')"
      ],
      "metadata": {
        "id": "P8O9LEIvlkjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd312a77-4712-4a0e-dade-5ff0fc8a371a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data transform:Compose(\n",
            "    TrivialAugmentWide(num_magnitude_bins=31, interpolation=InterpolationMode.NEAREST, fill=None)\n",
            "    ImageClassification(\n",
            "    crop_size=[288]\n",
            "    resize_size=[288]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BICUBIC\n",
            ")\n",
            ")\n",
            "Testing data transform:ImageClassification(\n",
            "    crop_size=[288]\n",
            "    resize_size=[288]\n",
            "    mean=[0.485, 0.456, 0.406]\n",
            "    std=[0.229, 0.224, 0.225]\n",
            "    interpolation=InterpolationMode.BICUBIC\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Getting data"
      ],
      "metadata": {
        "id": "vLTJdUrKl7qr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make data directory\n",
        "from pathlib import Path\n",
        "data_dir=Path('data')\n",
        "\n",
        "#Getting training data from Food101 dataset\n",
        "train_data=torchvision.datasets.Food101(root=data_dir,\n",
        "                                    split='train',\n",
        "                                    transform=food_101_transform,\n",
        "                                    download=True)\n",
        "\n",
        "#Get test data\n",
        "test_data=torchvision.datasets.Food101(root=data_dir,\n",
        "                                    split='test',\n",
        "                                    transform=effnet_transforms,\n",
        "                                    download=True)"
      ],
      "metadata": {
        "id": "UxtJpPELl9cB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d527fd2d-60d6-42f6-9424-1601f923673f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://data.vision.ee.ethz.ch/cvl/food-101.tar.gz to data/food-101.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4996278331/4996278331 [03:28<00:00, 24020455.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/food-101.tar.gz to data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[0][0]\n",
        "#get maximum and minimum values in test_data[0][0]\n",
        "test_data[0][0].max(),test_data[0][0].min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG_iI5gC67KO",
        "outputId": "70abeacd-cbb9-42c1-865d-307a31b478bf"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.6400), tensor(-2.0837))"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data.classes)\n",
        "print(f'Number of training samples: {len(train_data)}')\n",
        "print(f'Number of testing samples:{len(test_data)}')"
      ],
      "metadata": {
        "id": "eABPeyzXm-Cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f2a3683-047f-42d1-989e-115d04d756d3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['apple_pie', 'baby_back_ribs', 'baklava', 'beef_carpaccio', 'beef_tartare', 'beet_salad', 'beignets', 'bibimbap', 'bread_pudding', 'breakfast_burrito', 'bruschetta', 'caesar_salad', 'cannoli', 'caprese_salad', 'carrot_cake', 'ceviche', 'cheese_plate', 'cheesecake', 'chicken_curry', 'chicken_quesadilla', 'chicken_wings', 'chocolate_cake', 'chocolate_mousse', 'churros', 'clam_chowder', 'club_sandwich', 'crab_cakes', 'creme_brulee', 'croque_madame', 'cup_cakes', 'deviled_eggs', 'donuts', 'dumplings', 'edamame', 'eggs_benedict', 'escargots', 'falafel', 'filet_mignon', 'fish_and_chips', 'foie_gras', 'french_fries', 'french_onion_soup', 'french_toast', 'fried_calamari', 'fried_rice', 'frozen_yogurt', 'garlic_bread', 'gnocchi', 'greek_salad', 'grilled_cheese_sandwich', 'grilled_salmon', 'guacamole', 'gyoza', 'hamburger', 'hot_and_sour_soup', 'hot_dog', 'huevos_rancheros', 'hummus', 'ice_cream', 'lasagna', 'lobster_bisque', 'lobster_roll_sandwich', 'macaroni_and_cheese', 'macarons', 'miso_soup', 'mussels', 'nachos', 'omelette', 'onion_rings', 'oysters', 'pad_thai', 'paella', 'pancakes', 'panna_cotta', 'peking_duck', 'pho', 'pizza', 'pork_chop', 'poutine', 'prime_rib', 'pulled_pork_sandwich', 'ramen', 'ravioli', 'red_velvet_cake', 'risotto', 'samosa', 'sashimi', 'scallops', 'seaweed_salad', 'shrimp_and_grits', 'spaghetti_bolognese', 'spaghetti_carbonara', 'spring_rolls', 'steak', 'strawberry_shortcake', 'sushi', 'tacos', 'takoyaki', 'tiramisu', 'tuna_tartare', 'waffles']\n",
            "Number of training samples: 75750\n",
            "Number of testing samples:25250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save array returned by train_data.classes\n",
        "import pickle\n",
        "with open('train_classes.pkl','wb') as f:\n",
        "  pickle.dump(train_data.classes,f)"
      ],
      "metadata": {
        "id": "F3hUWiRUveFY"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make a subset of the dataset for faster expermenting"
      ],
      "metadata": {
        "id": "qCYB99mTn2wq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#make a function for splitting a dataset\n",
        "def split_dataset(dataset:torchvision.datasets, split_size:float=0.2, seed:int=69):\n",
        "  '''\n",
        "  Splits a given dataset to get a subset of the training dataset for faster expermentation\n",
        "  Put dataset in argument dataset and split_size in argument split_size\n",
        "  '''\n",
        "  length_1=int(len(dataset)*split_size)\n",
        "  length_2=len(dataset)-length_1\n",
        "\n",
        "  print(f\"Original dataset length:{len(dataset)}\")\n",
        "  print(f\"Length of first split:{length_1}\")\n",
        "  print(f\"Length of second split:{length_2}\")\n",
        "\n",
        "  #using torch.utils.data.random_split\n",
        "  random_split_1,random_split_2=torch.utils.data.random_split(dataset=dataset,\n",
        "                                                     lengths=[length_1,length_2],\n",
        "                                                     generator=torch.manual_seed(seed))\n",
        "  return random_split_1,random_split_2"
      ],
      "metadata": {
        "id": "6KrFvPwnSN4p"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#20% of training dataset\n",
        "train_data_20,_=split_dataset(dataset=train_data,\n",
        "                                         split_size=0.2,\n",
        "                                         seed=69)\n",
        "\n",
        "#20% of testing dataset\n",
        "test_data_20,_=split_dataset(dataset=test_data,\n",
        "                                         split_size=0.2,\n",
        "                                         seed=69)\n",
        "\n",
        "len(train_data_20),len(test_data_20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOVSQuaeVLnw",
        "outputId": "f211028f-bbbb-4602-c079-19b6cf3c6876"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset length:75750\n",
            "Length of first split:15150\n",
            "Length of second split:60600\n",
            "Original dataset length:25250\n",
            "Length of first split:5050\n",
            "Length of second split:20200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(15150, 5050)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8EDAjzqj3kN",
        "outputId": "cda8156f-bbc4-4edf-8d4e-13e542dbe15a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataset.Subset at 0x7982ace1add0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Make dataloaders for train_data_20 and test_data_20"
      ],
      "metadata": {
        "id": "kQIlQwuHV3yC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "BATCH_SIZE=32\n",
        "NUM_WORKERS=os.cpu_count()\n",
        "\n",
        "#Creating training dataloader using torch.utils.data.DataLoader()\n",
        "train_dataloader_20=torch.utils.data.DataLoader(dataset=train_data_20,\n",
        "                                                batch_size=32,\n",
        "                                                shuffle=True,\n",
        "                                                num_workers=NUM_WORKERS)\n",
        "\n",
        "#Creating testing dataloader using torch.utils.data.DataLoader()\n",
        "test_dataloader_20=torch.utils.data.DataLoader(dataset=test_data_20,\n",
        "                                               batch_size=32,\n",
        "                                               shuffle=False,\n",
        "                                               num_workers=NUM_WORKERS)\n",
        "\n",
        "#making full class_names list\n",
        "class_names=train_data.classes"
      ],
      "metadata": {
        "id": "r_YB4r2XWD9H"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training classifier layer of eff_net_b2"
      ],
      "metadata": {
        "id": "syjTQqnshxZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of Trainable parameters=142,309\n",
        "import engine\n",
        "\n",
        "#set optimizer\n",
        "optim=torch.optim.Adam(params=effnet_model.parameters(),\n",
        "                    lr=0.001)\n",
        "#setup loss function\n",
        "loss_fn=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "#set up scheduler\n",
        "scheduler=torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=optim,\n",
        "                                                     patience=0,\n",
        "                                                     mode='min',\n",
        "                                                     factor=0.2,\n",
        "                                                     verbose=True)\n",
        "\n",
        "#train\n",
        "effnet_results=engine.train(model=effnet_model,\n",
        "                            train_dataloader=train_dataloader_20,\n",
        "                            test_dataloader=test_dataloader_20,\n",
        "                            optimizer=optim,\n",
        "                            loss_fn=loss_fn,\n",
        "                            epochs=20,\n",
        "                            scheduler=scheduler,\n",
        "                            device=device)\n"
      ],
      "metadata": {
        "id": "FXfqz_r7h2zR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344,
          "referenced_widgets": [
            "2a774b80d53845568e391d6786a9ecb9",
            "7dfc49ef20474b80919bb26cdf536f61",
            "590bd1e196304f7da95132671a16ddd9",
            "a2ad59f18fd1447bb650eaacbf42da6d",
            "aa89cf4124e94e60bedf608f0110424c",
            "63438acf3403440e9e5a9d6f6393cdb0",
            "4ce57529dde64053965dedf6156914de",
            "5f6b72f2ecfb454bb30c1b8e2c5e25b9",
            "0df22fd22e8747078bb9a2f70f45e110",
            "ba0cb230ff1d40ebb0823fa42012093f",
            "3a63b85015b748b4a9276a5b776f7d74"
          ]
        },
        "outputId": "82a5de36-3365-41e7-ccfa-a5febb3f62ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a774b80d53845568e391d6786a9ecb9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/20 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:1|Train Loss:3.4160|Training Accuracy: 0.2910|Test Loss: 2.3544|Test Accuracy: 0.5098\n",
            "Epoch:2|Train Loss:2.4330|Training Accuracy: 0.4515|Test Loss: 1.9139|Test Accuracy: 0.5649\n",
            "Epoch:3|Train Loss:2.1368|Training Accuracy: 0.4950|Test Loss: 1.7617|Test Accuracy: 0.5776\n",
            "Epoch:4|Train Loss:1.9841|Training Accuracy: 0.5248|Test Loss: 1.7005|Test Accuracy: 0.5827\n",
            "Epoch:5|Train Loss:1.9018|Training Accuracy: 0.5345|Test Loss: 1.6262|Test Accuracy: 0.5955\n",
            "Epoch:6|Train Loss:1.8093|Training Accuracy: 0.5500|Test Loss: 1.5854|Test Accuracy: 0.6000\n",
            "Epoch:7|Train Loss:1.7482|Training Accuracy: 0.5633|Test Loss: 1.5794|Test Accuracy: 0.5960\n",
            "Epoch:8|Train Loss:1.7156|Training Accuracy: 0.5736|Test Loss: 1.5516|Test Accuracy: 0.6064\n",
            "Epoch:9|Train Loss:1.6864|Training Accuracy: 0.5723|Test Loss: 1.5620|Test Accuracy: 0.6035\n",
            "Epoch:10|Train Loss:1.5782|Training Accuracy: 0.6047|Test Loss: 1.5351|Test Accuracy: 0.6029\n",
            "Epoch:11|Train Loss:1.5543|Training Accuracy: 0.6089|Test Loss: 1.5297|Test Accuracy: 0.6045\n",
            "Epoch:12|Train Loss:1.5601|Training Accuracy: 0.6097|Test Loss: 1.5413|Test Accuracy: 0.6026\n",
            "Epoch:13|Train Loss:1.5365|Training Accuracy: 0.6185|Test Loss: 1.5415|Test Accuracy: 0.6056\n",
            "Epoch:14|Train Loss:1.5311|Training Accuracy: 0.6137|Test Loss: 1.5170|Test Accuracy: 0.6104\n",
            "Epoch:15|Train Loss:1.5274|Training Accuracy: 0.6187|Test Loss: 1.5318|Test Accuracy: 0.6054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Plot loss curves"
      ],
      "metadata": {
        "id": "gJk0BecGxwSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define function to take the values in th e dictionary and plot\n",
        "def plot_loss_curves(results):\n",
        "  train_loss=results['train_loss']\n",
        "  test_loss=results['test_loss']\n",
        "  train_accuracy=results['train_acc']\n",
        "  test_accuracy= results['test_acc']\n",
        "  epochs=range(len(results['train_loss']))\n",
        "  plt.figure(figsize=(16,8))\n",
        "\n",
        "  #plotting loss\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, train_loss, label='train loss')\n",
        "  plt.plot(epochs,test_loss, label='test loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend()\n",
        "  #plotting accuracy\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, train_accuracy, label='train accuracy')\n",
        "  plt.plot(epochs,test_accuracy, label='test accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('epochs')\n",
        "  plt.legend()"
      ],
      "metadata": {
        "id": "UT9tUvXPxzCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(effnet_results)"
      ],
      "metadata": {
        "id": "m93Ero9Ux3hP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Saving the model"
      ],
      "metadata": {
        "id": "87diUAydyrlf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving\n",
        "import utils\n",
        "utils.save_model(model=effnet_model,\n",
        "                 target_dir='models',\n",
        "                 model_name='pretrained_eff_net_feature_extractor.pth')"
      ],
      "metadata": {
        "id": "bPuSbrqJyze3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#checking model size\n",
        "from pathlib import Path\n",
        "eff_net_b2_size=Path('models/pretrained_eff_net_b2_feature_extractor.pth').stat().st_size//(1024*1024)#division converts bytes to MBs\n",
        "print(f\"The Pretrained EfficientNet_B2 feature extractor has size: {eff_net_b2_size} MB\")"
      ],
      "metadata": {
        "id": "vaDTylE2ytYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#counting number of parameters\n",
        "num_parameters=sum(p.numel() for p in effnet_model.parameters())\n",
        "print(f\"The pretrained EfficientNet_B2 feature extractor has {num_parameters} parameters\")"
      ],
      "metadata": {
        "id": "C3GGR8lyzGVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Deployment"
      ],
      "metadata": {
        "id": "oS3rzdJ41W5X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On HuggingFace using Docker"
      ],
      "metadata": {
        "id": "junx5D5YZLOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#making a folder contaaining examples\n",
        "#make list of 5 random image paths\n",
        "#import shutil\n",
        "#import random\n",
        "#n=5\n",
        "#get list of  n random integers between 0 and 5049 #5050 is length of test_data_20\n",
        "#image_index=[random.randint(0, 5049) for _ in range(n)]\n",
        "\n",
        "#for index in image_index:\n",
        "#  torchvision.io.write_jpeg(input=test_data_20[index][0],filename=f'examples/{index}.jpg')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "tn-mla7g011q",
        "outputId": "fad3c72d-2849-4e3c-a318-5a3b55866407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Input tensor dtype should be uint8",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-50-90ede661e8bc>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_index\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data_20\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'examples/{index}.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mwrite_jpeg\u001b[0;34m(input, filename, quality)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrite_jpeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m     \u001b[0mwrite_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mencode_jpeg\u001b[0;34m(input, quality)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image quality should be a positive number between 1 and 100\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquality\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 854\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Input tensor dtype should be uint8"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile model.py\n",
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "def create_effnet_b2(num_classes:int=101):\n",
        "  #1\n",
        "  weights=torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "  transforms=weights.transforms()\n",
        "  model=torchvision.models.efficientnet_b2(weights=weights).to(device)\n",
        "\n",
        "  #2. freeze all parameters in all layers\n",
        "  for param in model.parameters():\n",
        "    param.requires_grad=False\n",
        "  #3. set random seed\n",
        "  set_seeds()\n",
        "\n",
        "  #4. changing classifier layer\n",
        "  model.classifier= torch.nn.Sequential(nn.Dropout(p=0.2, inplace=True),\n",
        "                                        nn.Linear(in_features=1408,\n",
        "                                                  out_features=num_classes,\n",
        "                                                  bias=True).to(device))\n",
        "  #5. give name\n",
        "  model.name='effnet_b2'\n",
        "  print(f\"Making EfficientNet_B2\")\n",
        "\n",
        "  return model,weights,transforms"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWSx1yb4xaGG",
        "outputId": "10cca452-882e-4162-b4ce-349621482565"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import gradio as gr\n",
        "import os\n",
        "import torch\n",
        "from model import create_effnet_b2\n",
        "from PIL import Image\n",
        "from timeit import default_timer as timer\n",
        "from typing import Tuple, Dict\n",
        "import pickle\n",
        "\n",
        "#setup class names\n",
        "#unpickle data from file 'train_classes.pkl' and assign it to variable name class_names\n",
        "with open('train_classes.pkl','rb') as f:\n",
        "  class_names=pickle.load(f)\n",
        "\n",
        "###prepare model and transforms###\n",
        "\n",
        "#create effnetb2\n",
        "eff_net_b2,eff_net_b2_weights,eff_net_b2_transforms=create_effnet_b2(num_classes=len(class_names))\n",
        "\n",
        "#load saved weights\n",
        "eff_net_b2.load_state_dict(torch.load(f='models/pretrained_eff_net_b2_feature_extractor.pth',map_location=torch.device('cpu'))) #loading to cpu as gpu might not be available in all devices where model is used\n",
        "\n",
        "\n",
        "###Create Predict function###\n",
        "\n",
        "def predict(img)->Tuple[Dict,float]:\n",
        "  #start timer\n",
        "  start_time=timer()\n",
        "  #transform image\n",
        "  img=eff_net_b2_transforms(img).unsqueeze(0)\n",
        "  #put model in eval mode\n",
        "  eff_net_b2.eval()\n",
        "  with torch.inference_mode():\n",
        "    #pass image through model\n",
        "    pred_logits=eff_net_b2(img)\n",
        "    #get prediction probability\n",
        "    pred_prob=torch.softmax(pred_logits,dim=1)\n",
        "    #get prediction label\n",
        "    pred_label=torch.argmax(pred_prob,dim=1)\n",
        "\n",
        "    #make a dictionary of class name and corresponding prediction probability of the class\n",
        "    prob_dict={class_names[i]:pred_prob[0][i].item() for i in range(len(class_names))}\n",
        "\n",
        "    #end timer and calculate time\n",
        "    end_time=timer()\n",
        "    time_elapsed=round(end_time-start_time,4)\n",
        "\n",
        "  #return the dictionary and time\n",
        "  return prob_dict, time_elapsed\n",
        "\n",
        "\n",
        "\n",
        "###Gradio App##\n",
        "\n",
        "#create title, description and articles\n",
        "title=\"Food Prediction\"\n",
        "description='Takes an image as input and classifies it into sushi, pizza or steak'\n",
        "article=\"Created in colab, github link:https://github.com/FrodoBaggins87/Machine_Learning/blob/main/Model_Deployment.ipynb\"\n",
        "\n",
        "#create example list\n",
        "#example_list=[['examples/'+ example] for example in os.listdir('demo/food_prediction/examples')]\n",
        "\n",
        "#create gradio interface\n",
        "demo=gr.Interface(fn=predict,\n",
        "                 inputs=gr.Image(type='pil'),\n",
        "                 outputs=[gr.Label(num_top_classes=3,label='Prediction'),\n",
        "                          gr.Number(label='Time Elapsed')],#Have to add examples here\n",
        "                 title=title,\n",
        "                 description=description,\n",
        "                 article=article)\n",
        "\n",
        "#launch demo\n",
        "demo.launch(debug=False,share=True)"
      ],
      "metadata": {
        "id": "wGdKQ_911WA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e45cdba-8468-4116-dd2c-37a536ce9c9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    }
  ]
}